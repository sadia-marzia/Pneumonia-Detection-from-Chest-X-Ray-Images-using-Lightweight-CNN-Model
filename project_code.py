# -*- coding: utf-8 -*-
"""Term Paper1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mh0vzCa0Go1HEIVQDZC599DKoqiOo89U

# **Lightweight CNN Model for Efficient Pneumonia Detection from Chest X-Ray Images**

# **Image amount check**
"""

import os

# Set the path to your main dataset folder (update this)
dataset_path = '/content/drive/MyDrive/CHESTXRAY/'  # example path

# List subfolders (Normal and Pneumonia)
folders = os.listdir(dataset_path)

print("ðŸ“‚ Dataset summary:\n")
for folder in folders:
    folder_path = os.path.join(dataset_path, folder)
    if os.path.isdir(folder_path):
        num_images = len(os.listdir(folder_path))
        print(f"{folder}: {num_images} images")

"""# **Visualize samples**"""

import os
import matplotlib.pyplot as plt
import random
import cv2

# Path to dataset
dataset_path = '/content/drive/MyDrive/CHESTXRAY/'

# List of classes
classes = ['NORMAL', 'PNEUMONIA']

plt.figure(figsize=(10, 6))

for i, cls in enumerate(classes):
    folder_path = os.path.join(dataset_path, cls)
    # Pick 3 random images from the folder
    sample_images = random.sample(os.listdir(folder_path), 3)

    for j, img_name in enumerate(sample_images):
        img_path = os.path.join(folder_path, img_name)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        plt.subplot(2, 3, i*3 + j + 1)
        plt.imshow(img)
        plt.title(cls)
        plt.axis('off')

plt.suptitle("Sample Chest X-ray Images (Normal vs Pneumonia)", fontsize=14)
plt.tight_layout()
plt.show()

"""# **Resizing to 224x224**"""

import os
import cv2
from tqdm import tqdm

# Paths
input_dir = '/content/drive/MyDrive/CHESTXRAY/'          # original folder
output_dir = '/content/drive/MyDrive/CHESTXRAY_RESIZED/' # resized folder
target_size = (224, 224)  # resize size (width, height)

# Create output directories if not exist
os.makedirs(output_dir, exist_ok=True)

# Loop through each class folder (NORMAL, PNEUMONIA)
for folder in os.listdir(input_dir):
    input_folder = os.path.join(input_dir, folder)
    output_folder = os.path.join(output_dir, folder)

    if not os.path.isdir(input_folder):
        continue  # skip files

    os.makedirs(output_folder, exist_ok=True)

    print(f"Processing {folder}...")

    # Loop through images in each folder
    for img_name in tqdm(os.listdir(input_folder)):
        img_path = os.path.join(input_folder, img_name)

        try:
            # Read image
            img = cv2.imread(img_path)
            if img is None:
                continue

            # Resize
            img_resized = cv2.resize(img, target_size)

            # Save resized image to output folder
            save_path = os.path.join(output_folder, img_name)
            cv2.imwrite(save_path, img_resized)

        except Exception as e:
            print(f"Error processing {img_name}: {e}")

print("\nâœ… All images resized and saved successfully in:", output_dir)

"""# **Preprocessing**"""

import os
import cv2
import numpy as np
from tqdm import tqdm

input_dir = '/content/drive/MyDrive/CHESTXRAY_RESIZED/'
output_dir = '/content/drive/MyDrive/CHESTXRAY_PREPROCESSED_V2/'

os.makedirs(output_dir, exist_ok=True)

for folder in os.listdir(input_dir):
    input_folder = os.path.join(input_dir, folder)
    output_folder = os.path.join(output_dir, folder)

    if not os.path.isdir(input_folder):
        continue

    os.makedirs(output_folder, exist_ok=True)
    print(f"Processing {folder}...")

    for img_name in tqdm(os.listdir(input_folder)):
        img_path = os.path.join(input_folder, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            continue

        # --- Step 1: Denoise using Median Filter (preserves edges) ---
        #img_denoised = cv2.medianBlur(img, 3)

        # --- Step 2: Contrast enhancement using CLAHE ---
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(6,6))
        img_clahe = clahe.apply(img)

        # --- Step 3: Gamma correction (optional, improves brightness) ---
        gamma = 1.2  # try between 1.0 and 1.5
        img_gamma = np.power(img_clahe / 255.0, gamma)

        # --- Step 4: Normalize to 0â€“1 ---
        img_norm = (img_gamma - np.min(img_gamma)) / (np.max(img_gamma) - np.min(img_gamma))

        # --- Save ---
        save_path = os.path.join(output_folder, img_name)
        img_to_save = np.uint8(img_norm * 255)
        cv2.imwrite(save_path, img_to_save)

print("\nâœ… Improved preprocessing completed and saved in:", output_dir)

"""# **Train-Validation-test split**"""

import os
import shutil
import random
from tqdm import tqdm
import os
import shutil
import random
from tqdm import tqdm

# Original folder
data_dir = '../input/chestxray/CHESTXRAY_PREPROCESSED_V2/'

# Output folder for splits
split_dir = '/content/drive/MyDrive/CHESTXRAY_SPLIT/'
os.makedirs(split_dir, exist_ok=True)

splits = ['train','val','test']
classes = ['NORMAL','PNEUMONIA']

for s in splits:
    for c in classes:
        os.makedirs(os.path.join(split_dir, s, c), exist_ok=True)

# Split ratios
train_ratio = 0.7
val_ratio = 0.1
test_ratio = 0.2

random.seed(42)

for cls in classes:
    src_folder = os.path.join(data_dir, cls)
    images = [f for f in os.listdir(src_folder) if f.lower().endswith(('jpg','jpeg','png'))]
    random.shuffle(images)

    n_total = len(images)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)
    n_test = n_total - n_train - n_val

    train_files = images[:n_train]
    val_files = images[n_train:n_train+n_val]
    test_files = images[n_train+n_val:]

    # Copy files
    for subset, files in zip(['train','val','test'], [train_files, val_files, test_files]):
        for f in tqdm(files, desc=f"{cls} â†’ {subset}", leave=False):
            shutil.copy(os.path.join(src_folder, f), os.path.join(split_dir, subset, cls, f))

    print(f"{cls}: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}")

print("\nâœ… Dataset split complete!")
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img

train_dir = os.path.join(split_dir, 'train')
target_count = 4000
img_size = (224,224)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

for cls in classes:
    folder = os.path.join(train_dir, cls)
    images = [f for f in os.listdir(folder) if f.lower().endswith(('jpg','jpeg','png'))]
    n_existing = len(images)
    print(f"\n{cls}: {n_existing} original images in training set")

    loaded_images = []
    for f in tqdm(images, desc=f"Loading {cls} images"):
        try:
            img = load_img(os.path.join(folder,f), target_size=img_size, color_mode='grayscale')
            loaded_images.append(img_to_array(img))
        except:
            continue

    count = n_existing
    counter = 0
    while count < target_count:
        x = loaded_images[np.random.randint(0,len(loaded_images))].reshape((1,) + img_size + (1,))
        prefix = f"aug_{cls.lower()}_{counter:05d}"
        for _ in datagen.flow(x, batch_size=1, save_to_dir=folder, save_prefix=prefix, save_format='jpeg'):
            count += 1
            counter += 1
            if count >= target_count:
                break
    print(f"{cls}: Final training images = {count}")

"""# **Proposed Model**"""

import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

batch_size = 32

# Data generators
train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'train'),
    target_size=img_size,
    color_mode='grayscale',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)
val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'val'),
    target_size=img_size,
    color_mode='grayscale',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)
test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'test'),
    target_size=img_size,
    color_mode='grayscale',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# Define L2 regularization strength (common values: 1e-3 to 1e-5)
l2_reg = regularizers.l2(1e-4)


model = models.Sequential([
    layers.Conv2D(32, (3,3), padding='same', kernel_regularizer=l2_reg, input_shape=(224,224,1)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), padding='same', kernel_regularizer=l2_reg),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128, (3,3), padding='same', kernel_regularizer=l2_reg),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    # âœ… Replace Flatten with GAP
    layers.GlobalAveragePooling2D(),

    layers.Dense(256, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])


model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),
              loss='binary_crossentropy',
              metrics=['accuracy'])
# ---------------------
# Display Model Summary
# ---------------------
print("\nðŸ“ Model Architecture:")
model.summary()
early_stop = EarlyStopping(
    monitor='val_loss',    # monitor validation loss
    patience=5,            # stop after 5 epochs of no improvement
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # monitor validation loss
    factor=0.5,            # reduce LR by factor
    patience=2,            # wait 3 epochs before reducing
    min_lr=1e-7,           # minimum LR
    verbose=1
)
# Train
history = model.fit(
    train_gen,
    epochs=50,               # you can increase epochs, early stopping will stop earlier if needed
    validation_data=val_gen,
    callbacks=[early_stop, reduce_lr]
)
# Accuracy/Loss Plots
plt.figure(figsize=(10,4))

# Accuracy Plot
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'][:30], label='Train Acc')
plt.plot(history.history['val_accuracy'][:30], label='Val Acc')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training & Validation Accuracy (First 30 Epochs)')
plt.legend()

# Loss Plot
plt.subplot(1,2,2)
plt.plot(history.history['loss'][:30], label='Train Loss')
plt.plot(history.history['val_loss'][:30], label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training & Validation Loss (First 30 Epochs)')
plt.legend()

plt.tight_layout()
plt.show()

# Test evaluation
test_loss, test_acc = model.evaluate(test_gen)
print(f"\nðŸ§ª Test Accuracy: {test_acc*100:.2f}%")

# Predictions
y_true = test_gen.classes
y_pred_prob = model.predict(test_gen)
y_pred = (y_pred_prob>0.5).astype(int).ravel()

# Classification report
print("\nðŸ“Š Classification Report:")
print(classification_report(y_true, y_pred, target_names=['NORMAL','PNEUMONIA']))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL','PNEUMONIA'], yticklabels=['NORMAL','PNEUMONIA'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC-AUC
roc_auc = roc_auc_score(y_true, y_pred_prob)
fpr,tpr,_ = roc_curve(y_true, y_pred_prob)
plt.plot(fpr,tpr,label=f"ROC curve (AUC={roc_auc:.3f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC-AUC Curve")
plt.legend()
plt.show()

"""# **inception V3**"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications import InceptionV3
batch_size = 32
# ----------------------
# Data Generators
# ----------------------
train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'train'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)
val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'val'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)
test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'test'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)


# CNN Model
from tensorflow.keras import layers, models

# ----------------------
# Load Pretrained InceptionV3
# ----------------------
base_model = InceptionV3(
    weights='imagenet',
    include_top=False,          # remove default classifier
    input_shape=(img_size[0], img_size[1], 3)
)

# Freeze base layers for transfer learning
base_model.trainable = False

# ----------------------
# Add Custom Classifier
# ----------------------
x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
predictions = layers.Dense(1, activation='sigmoid')(x)  # binary classification

model = models.Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
              loss='binary_crossentropy',
              metrics=['accuracy'])
# ---------------------
# Display Model Summary
# ---------------------
print("\nðŸ“ Model Architecture:")
model.summary()
early_stop = EarlyStopping(
    monitor='val_loss',    # monitor validation loss
    patience=5,            # stop after 5 epochs of no improvement
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # monitor validation loss
    factor=0.5,            # reduce LR by factor
    patience=2,            # wait 3 epochs before reducing
    min_lr=1e-7,           # minimum LR
    verbose=1
)
# Train
history = model.fit(
    train_gen,
    epochs=40,               # you can increase epochs, early stopping will stop earlier if needed
    validation_data=val_gen,
    callbacks=[early_stop]
)
# Accuracy/Loss Plots
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend(); plt.title("Accuracy")

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title("Loss")
plt.show()

# Test evaluation
test_loss, test_acc = model.evaluate(test_gen)
print(f"\nðŸ§ª Test Accuracy: {test_acc*100:.2f}%")

# Predictions
y_true = test_gen.classes
y_pred_prob = model.predict(test_gen)
y_pred = (y_pred_prob>0.5).astype(int).ravel()

# Classification report
print("\nðŸ“Š Classification Report:")
print(classification_report(y_true, y_pred, target_names=['NORMAL','PNEUMONIA']))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL','PNEUMONIA'], yticklabels=['NORMAL','PNEUMONIA'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC-AUC
roc_auc = roc_auc_score(y_true, y_pred_prob)
fpr,tpr,_ = roc_curve(y_true, y_pred_prob)
plt.plot(fpr,tpr,label=f"ROC curve (AUC={roc_auc:.3f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC-AUC Curve")
plt.legend()
plt.show()

"""# **ResNet50**"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications import ResNet50
batch_size = 32
# ----------------------
# Data Generators
# ----------------------
train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'train'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)
val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'val'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)
test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'test'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)


# CNN Model
from tensorflow.keras import layers, models

# ----------------------
# Load Pretrained ResNet50
# ----------------------
base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(img_size[0], img_size[1], 3)
)
base_model.trainable = False  # freeze base

# ----------------------
# Add Custom Classifier
# ----------------------
x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
predictions = layers.Dense(1, activation='sigmoid')(x)  # binary classification

model = models.Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
              loss='binary_crossentropy',
              metrics=['accuracy'])
# ---------------------
# Display Model Summary
# ---------------------
print("\nðŸ“ Model Architecture:")
model.summary()
early_stop = EarlyStopping(
    monitor='val_loss',    # monitor validation loss
    patience=5,            # stop after 5 epochs of no improvement
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # monitor validation loss
    factor=0.5,            # reduce LR by factor
    patience=2,            # wait 3 epochs before reducing
    min_lr=1e-7,           # minimum LR
    verbose=1
)
# Train
history = model.fit(
    train_gen,
    epochs=40,               # you can increase epochs, early stopping will stop earlier if needed
    validation_data=val_gen,
    callbacks=[early_stop]
)
# Accuracy/Loss Plots
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend(); plt.title("Accuracy")

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title("Loss")
plt.show()

# Test evaluation
test_loss, test_acc = model.evaluate(test_gen)
print(f"\nðŸ§ª Test Accuracy: {test_acc*100:.2f}%")

# Predictions
y_true = test_gen.classes
y_pred_prob = model.predict(test_gen)
y_pred = (y_pred_prob>0.5).astype(int).ravel()

# Classification report
print("\nðŸ“Š Classification Report:")
print(classification_report(y_true, y_pred, target_names=['NORMAL','PNEUMONIA']))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL','PNEUMONIA'], yticklabels=['NORMAL','PNEUMONIA'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC-AUC
roc_auc = roc_auc_score(y_true, y_pred_prob)
fpr,tpr,_ = roc_curve(y_true, y_pred_prob)
plt.plot(fpr,tpr,label=f"ROC curve (AUC={roc_auc:.3f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC-AUC Curve")
plt.legend()
plt.show()

"""# **DenseNet121**"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications import DenseNet121
batch_size = 32
# ----------------------
# Data Generators
# ----------------------
train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'train'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)
val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'val'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)
test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'test'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)


# CNN Model
from tensorflow.keras import layers, models

# ----------------------
# Load Pretrained DenseNet121
# ----------------------
base_model = DenseNet121(
    weights='imagenet',
    include_top=False,
    input_shape=(img_size[0], img_size[1], 3)
)
base_model.trainable = False

# ----------------------
# Add Custom Classifier
# ----------------------
x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
predictions = layers.Dense(1, activation='sigmoid')(x)  # binary classification

model = models.Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
              loss='binary_crossentropy',
              metrics=['accuracy'])
# ---------------------
# Display Model Summary
# ---------------------
print("\nðŸ“ Model Architecture:")
model.summary()
early_stop = EarlyStopping(
    monitor='val_loss',    # monitor validation loss
    patience=5,            # stop after 5 epochs of no improvement
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # monitor validation loss
    factor=0.5,            # reduce LR by factor
    patience=2,            # wait 3 epochs before reducing
    min_lr=1e-7,           # minimum LR
    verbose=1
)
# Train
history = model.fit(
    train_gen,
    epochs=40,               # you can increase epochs, early stopping will stop earlier if needed
    validation_data=val_gen,
    callbacks=[early_stop]
)
# Accuracy/Loss Plots
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend(); plt.title("Accuracy")

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title("Loss")
plt.show()

# Test evaluation
test_loss, test_acc = model.evaluate(test_gen)
print(f"\nðŸ§ª Test Accuracy: {test_acc*100:.2f}%")

# Predictions
y_true = test_gen.classes
y_pred_prob = model.predict(test_gen)
y_pred = (y_pred_prob>0.5).astype(int).ravel()

# Classification report
print("\nðŸ“Š Classification Report:")
print(classification_report(y_true, y_pred, target_names=['NORMAL','PNEUMONIA']))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL','PNEUMONIA'], yticklabels=['NORMAL','PNEUMONIA'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC-AUC
roc_auc = roc_auc_score(y_true, y_pred_prob)
fpr,tpr,_ = roc_curve(y_true, y_pred_prob)
plt.plot(fpr,tpr,label=f"ROC curve (AUC={roc_auc:.3f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC-AUC Curve")
plt.legend()
plt.show()

"""# **EfficientNetB0**"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications import EfficientNetB0
batch_size = 32
# ----------------------
# Data Generators
# ----------------------
train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'train'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)
val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'val'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)
test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    os.path.join(split_dir,'test'),
    target_size=img_size,
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)


# CNN Model
from tensorflow.keras import layers, models

# ----------------------
# Load Pretrained EfficientNetB0
# ----------------------
base_model = EfficientNetB0(
    weights='imagenet',
    include_top=False,
    input_shape=(img_size[0], img_size[1], 3)
)
base_model.trainable = False

# ----------------------
# Add Custom Classifier
# ----------------------
x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
predictions = layers.Dense(1, activation='sigmoid')(x)  # binary classification

model = models.Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
              loss='binary_crossentropy',
              metrics=['accuracy'])
# ---------------------
# Display Model Summary
# ---------------------
print("\nðŸ“ Model Architecture:")
model.summary()
early_stop = EarlyStopping(
    monitor='val_loss',    # monitor validation loss
    patience=5,            # stop after 5 epochs of no improvement
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',    # monitor validation loss
    factor=0.5,            # reduce LR by factor
    patience=2,            # wait 3 epochs before reducing
    min_lr=1e-7,           # minimum LR
    verbose=1
)
# Train
history = model.fit(
    train_gen,
    epochs=40,               # you can increase epochs, early stopping will stop earlier if needed
    validation_data=val_gen,
    callbacks=[early_stop]
)
# Accuracy/Loss Plots
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend(); plt.title("Accuracy")

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title("Loss")
plt.show()

# Test evaluation
test_loss, test_acc = model.evaluate(test_gen)
print(f"\nðŸ§ª Test Accuracy: {test_acc*100:.2f}%")

# Predictions
y_true = test_gen.classes
y_pred_prob = model.predict(test_gen)
y_pred = (y_pred_prob>0.5).astype(int).ravel()

# Classification report
print("\nðŸ“Š Classification Report:")
print(classification_report(y_true, y_pred, target_names=['NORMAL','PNEUMONIA']))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL','PNEUMONIA'], yticklabels=['NORMAL','PNEUMONIA'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC-AUC
roc_auc = roc_auc_score(y_true, y_pred_prob)
fpr,tpr,_ = roc_curve(y_true, y_pred_prob)
plt.plot(fpr,tpr,label=f"ROC curve (AUC={roc_auc:.3f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC-AUC Curve")
plt.legend()
plt.show()
